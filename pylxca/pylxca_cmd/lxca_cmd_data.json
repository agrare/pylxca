{
  "nodes": [
    "u:s:c:v:h", 
    [
      "con=",
      "uuid=",
      "status=",
      "chassis=",
      "view="
    ], 
    [], 
    "Get nodes inventory", 
    "\nUsage: nodes [-h] [-u <UUID>] [-s <manage/unmanaged>] [-c <chassis UUID>] [-v <view filter name>] \n\n\toptional arguments:\n\t-h\t\tshow this help message\n\t-u, --uuid=\tnode uuid\n\t-s, --status=\tnodes manage status (managed/unmanaged)\n\t-c, --chassis=\tchassis uuid\n\t-v, --view=\tview filter name"
  ],
  "chassis": [
    "u:s:v:h", 
    [
      "con=",
      "uuid=",
      "status=",
      "view="
    ], 
    [], 
    "Get chassis inventory", 
    "\nUsage: chassis [-h] [-u <UUID>] [-v <view filter name>]\n\n\toptional arguments:\n\t-h\t\tshow this help message\n\t-u, --uuid=\tchassis uuid\n\t-s, --status=\tchassis manage status (managed/unmanaged)\n\t-v, --view=\tview filter name"
  ], 
  "switches": [
    "u:c:v:h", 
    [
      "con=",
	  "uuid=",
      "chassis=",
      "view="
    ], 
    [], 
    "Get switches inventory", 
    "\nUsage: switches [-h] [-u <UUID>] [-c <chassis UUID>] [-v <view filter name>]\n\n\toptional arguments:\n\t-h\t\tshow this help message\n\t-u, --uuid=\tswitch uuid\n\t-c, --chassis=\tchassis uuid\n\t-v, --view=\tview filter name"
  ],
  "fans": [
    "u:c:v:h", 
    [
      "con=",
	  "uuid=",
      "chassis=",
      "view="
    ], 
    [], 
    "Get fans inventory", 
    "\nUsage: fans [-h] [-u <UUID>] [-c <chassis UUID>] [-v <view filter name>]\n\n\toptional arguments:\n\t-h\t\tshow this help message\n\t-u, --uuid=\tfan uuid\n\t-c, --chassis=\tchassis uuid\n\t-v, --view=\tview filter name"
  ],
  "powersupplies": [
    "u:c:v:h", 
    [
      "con=",
	  "uuid=",
      "chassis=",
      "view="
    ], 
    [], 
    "Get Power Supply inventory", 
    "\nUsage: powersupplies [-h] [-u <UUID>] [-c <chassis UUID>] [-v <view filter name>]\n\n\toptional arguments:\n\t-h\t\tshow this help message\n\t-u, --uuid=\tpower supply uuid\n\t-c, --chassis=\tchassis uuid\n\t-v, --view=\tview filter name"
  ],
  "fanmuxes": [
    "u:c:v:h", 
    [
      "con=",
	  "uuid=",
      "chassis=",
      "view="
    ], 
    [], 
    "Get Fan Mux inventory", 
    "\nUsage: fanmuxes [-h] [-u <UUID>] [-c <chassis UUID>] [-v <view filter name>]\n\n\toptional arguments:\n\t-h\t\tshow this help message\n\t-u, --uuid=\tfan mux uuid\n\t-c, --chassis=\tchassis uuid\n\t-v, --view=\tview filter name"
  ],
  "cmms": [
    "u:c:v:h", 
    [
      "con=",
	  "uuid=",
      "chassis=",
      "view="
    ], 
    [], 
    "Get CMM inventory", 
    "\nUsage: cmms [-h] [-u <UUID>] [-c <chassis UUID>] [-v <view filter name>]\n\n\toptional arguments:\n\t-h\t\tshow this help message\n\t-u, --uuid=\tcmm uuid\n\t-c, --chassis=\tchassis uuid\n\t-v, --view=\tview filter name"
  ],
  "scalablesystem": [
    "i:t:v:s:h", 
    [
      "con=",
      "id=",
      "type=",
      "status=",
      "view="
    ], 
    [], 
    "Get Scalable Complex System inventory", 
    "\nUsage: scalablesystem [-h] [-i <id>] [-t <type>] [-s <status>] [-v <view filter name>]\n\n\toptional arguments:\n\t-h\t\tshow this help message\n\t-i, --id=\tscalable complex id\n\t-t, --type=\ttype (flex/rackserver)\n\t-s, --status=\tscalable system manage status (managed/unmanaged)\n\t-v, --view=\tview filter name"
  ],
  "connect": [
    "u:l:p:h", 
    [
      "url=", 
      "user=",
      "pw=",
      "noverify"
    ], 
    [
      [
        "-u", 
        "--user"
      ], 
      [
        "-l", 
        "--url"
      ]
    ], 
    "Connect LXCA", 
    "\nUsage: connect [-h] [-l <URL>] [-u <USER>] [--noverify] \n\n\toptional arguments:\n\t-h\t\tshow this help message\n\t--noverify\tdo not verify server certificate\n\tmandatory arguments\n\t-l, --url=\turl of LXCA\n\t-u, --user=\tusername to authenticate\n"
  ], 
  "log": [
    "l:h", 
    [
      "lvl="
    ], 
    [], 
    "Get/set log level of Python LXCA", 
    "\nUsage: log [-l <level>] \n\t-l, --lvl=\tlogging level\n"
  ],
  "disconnect": [
    "h", 
    [], 
    [], 	
    "Disconnect LXCA", 
    "\nUsage: disconnect"
  ],
  "ostream": [
    "l:h",
    [
      "lvl="
    ],
    [],
    "Set ostream level of PYLXCA Interactive Shell",
    "\nUsage: ostream [-l <level>]\n\t-l, --lvl=\tverbose level\n"
  ],
  "jobs": [
    "i:u:s:c:d:h",
    [
      "con=",
 	  "id=",	
      "uuid=",
      "state=",
      "cancel=",
      "delete="
    ],
    [],
    "Retrieve and manage job information",
    "\nUsage: jobs  [-i <job id>][-u <uuid of endpoint>][-s <jobs state>][-c <cancels the job with specified id>][-d <delete the job with specified id>]\n\n\toptional arguments:\n\t-i, --id=\tjob id\n\t-u, --uuid=\tuuid of endpoint for which jobs should be retrieved\n\t-s, --state=\tjob state to retrieve jobs in specified state\n\t-c, --cancel\tcancel job of specified id\n\t-d, --delete\tdelete job of specified id\n"
  ],
  "discover": [
    "h",
    [
      "con="
    ],
    [],
    "Retrieve a list of devices discovered by SLP discovery.",
    "\nUsage: discover  "
  ]
}
